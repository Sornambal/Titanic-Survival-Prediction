{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+KNfHk1hjV7tYsLxkThsq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sornambal/Titanic-Survival-Prediction/blob/main/Titanic_Survival_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVVgzR3vXxSp",
        "outputId": "4e74d899-220b-4e77-9940-1c7d18586bec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "!pip install catboost\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from catboost import CatBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Load data (adjust path if needed)\n",
        "train = pd.read_csv(\"/content/train.csv\")\n",
        "test  = pd.read_csv(\"/content/test.csv\")"
      ],
      "metadata": {
        "id": "_MCGXbQgYPph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save original PassengerId for submission\n",
        "test_ids = test[\"PassengerId\"].copy()"
      ],
      "metadata": {
        "id": "66Nb8_YjYPmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 3) Combine for unified feature engineering\n",
        "df = pd.concat([train, test], sort=False, ignore_index=True)"
      ],
      "metadata": {
        "id": "N40KqojEYPjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Basic fills\n",
        "df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].median())\n",
        "df[\"Fare\"] = df[\"Fare\"].fillna(df[\"Fare\"].median())\n",
        "df[\"Embarked\"] = df[\"Embarked\"].fillna(df[\"Embarked\"].mode()[0])"
      ],
      "metadata": {
        "id": "ZCASdTCUYu57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Basic features\n",
        "df[\"Sex\"] = df[\"Sex\"].map({\"male\":0, \"female\":1})\n",
        "df[\"FamilySize\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\n",
        "df[\"IsAlone\"] = (df[\"FamilySize\"] == 1).astype(int)\n",
        "df[\"FarePerPerson\"] = df[\"Fare\"] / df[\"FamilySize\"]"
      ],
      "metadata": {
        "id": "o0QEt4owYuqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) Titles & surname\n",
        "df[\"Title\"] = df[\"Name\"].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
        "df[\"Title\"] = df[\"Title\"].replace({\n",
        "    'Mlle':'Miss', 'Ms':'Miss', 'Mme':'Mrs',\n",
        "    'Countess':'Rare','Lady':'Rare','Dona':'Rare',\n",
        "    'Don':'Rare','Sir':'Rare','Jonkheer':'Rare',\n",
        "    'Capt':'Rare','Col':'Rare','Major':'Rare','Rev':'Rare','Dr':'Rare'\n",
        "})\n",
        "\n",
        "df[\"Surname\"] = df[\"Name\"].apply(lambda x: x.split(\",\")[0].strip())"
      ],
      "metadata": {
        "id": "Qnl87shaYum8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7) Ticket prefix and group\n",
        "def ticket_prefix(t):\n",
        "    t = str(t)\n",
        "    t = t.replace('.', '').replace('/', '').strip()\n",
        "    parts = t.split()\n",
        "    pref = ''.join([p for p in parts if not p.isdigit()])\n",
        "    return pref if pref != \"\" else \"NONE\"\n",
        "\n",
        "df[\"TicketPrefix\"] = df[\"Ticket\"].apply(ticket_prefix)\n",
        "df[\"TicketGroup\"] = df.groupby(\"Ticket\")[\"Ticket\"].transform(\"count\")\n"
      ],
      "metadata": {
        "id": "SNA8ZtEKYukV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8) Cabin / Deck extraction\n",
        "df[\"Cabin\"] = df[\"Cabin\"].fillna(\"Unknown\")\n",
        "df[\"Deck\"] = df[\"Cabin\"].astype(str).str[0]\n",
        "df[\"Deck\"] = df[\"Deck\"].replace(\"n\", \"Unknown\").replace(\"\", \"Unknown\")\n"
      ],
      "metadata": {
        "id": "SMwD8z6aY6AK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9) Create survival signals from TRAIN data (leaks)\n",
        "# We compute surname-level, ticket-level, family-size level historical survival rates using only TRAIN rows.\n",
        "train_rows = df.loc[:len(train)-1].copy()\n",
        "\n",
        "# surname survival: mean and count\n",
        "surname_stats = train_rows.groupby(\"Surname\")[\"Survived\"].agg([\"mean\",\"count\"]).reset_index().rename(columns={\"mean\":\"SurnameSurvivalRate\",\"count\":\"SurnameCount\"})\n",
        "surname_stats_dict = surname_stats.set_index(\"Surname\").to_dict(orient=\"index\")\n",
        "\n",
        "# ticket survival\n",
        "ticket_stats = train_rows.groupby(\"Ticket\")[\"Survived\"].agg([\"mean\",\"count\"]).reset_index().rename(columns={\"mean\":\"TicketSurvivalRate\",\"count\":\"TicketCount\"})\n",
        "ticket_stats_dict = ticket_stats.set_index(\"Ticket\").to_dict(orient=\"index\")\n",
        "\n",
        "# family size survival\n",
        "familysize_stats = train_rows.groupby(\"FamilySize\")[\"Survived\"].mean().to_dict()\n",
        "\n",
        "# deck survival\n",
        "deck_stats = train_rows.groupby(\"Deck\")[\"Survived\"].agg([\"mean\",\"count\"]).reset_index().rename(columns={\"mean\":\"DeckSurvivalRate\",\"count\":\"DeckCount\"})\n",
        "deck_stats_dict = deck_stats.set_index(\"Deck\").to_dict(orient=\"index\")\n",
        "\n",
        "# Apply mapping to full df (fill unknowns)\n",
        "df[\"SurnameSurvivalRate\"] = df[\"Surname\"].map(lambda s: surname_stats_dict.get(s, {\"SurnameSurvivalRate\":np.nan})[\"SurnameSurvivalRate\"])\n",
        "df[\"SurnameCount\"] = df[\"Surname\"].map(lambda s: surname_stats_dict.get(s, {\"SurnameCount\":0})[\"SurnameCount\"])\n",
        "\n",
        "df[\"TicketSurvivalRate\"] = df[\"Ticket\"].map(lambda t: ticket_stats_dict.get(t, {\"TicketSurvivalRate\":np.nan})[\"TicketSurvivalRate\"])\n",
        "df[\"TicketCount\"] = df[\"Ticket\"].map(lambda t: ticket_stats_dict.get(t, {\"TicketCount\":0})[\"TicketCount\"])\n",
        "\n",
        "df[\"FamilySizeSurvivalRate\"] = df[\"FamilySize\"].map(lambda fs: familysize_stats.get(fs, np.nan))\n",
        "\n",
        "df[\"DeckSurvivalRate\"] = df[\"Deck\"].map(lambda d: deck_stats_dict.get(d, {\"DeckSurvivalRate\":np.nan})[\"DeckSurvivalRate\"])\n",
        "df[\"DeckCount\"] = df[\"Deck\"].map(lambda d: deck_stats_dict.get(d, {\"DeckCount\":0})[\"DeckCount\"])\n",
        "\n",
        "# Fill missing survival rates with neutral 0.5\n",
        "df[\"SurnameSurvivalRate\"] = df[\"SurnameSurvivalRate\"].fillna(0.5)\n",
        "df[\"TicketSurvivalRate\"] = df[\"TicketSurvivalRate\"].fillna(0.5)\n",
        "df[\"FamilySizeSurvivalRate\"] = df[\"FamilySizeSurvivalRate\"].fillna(0.5)\n",
        "df[\"DeckSurvivalRate\"] = df[\"DeckSurvivalRate\"].fillna(0.5)\n"
      ],
      "metadata": {
        "id": "GnlsqPUVY8Dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreate Title if missing\n",
        "if \"Title\" not in df.columns:\n",
        "    df[\"Title\"] = df[\"Name\"].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
        "    df[\"Title\"] = df[\"Title\"].replace({\n",
        "        'Mlle':'Miss', 'Ms':'Miss', 'Mme':'Mrs',\n",
        "        'Countess':'Rare','Lady':'Rare','Dona':'Rare',\n",
        "        'Don':'Rare','Sir':'Rare','Jonkheer':'Rare',\n",
        "        'Capt':'Rare','Col':'Rare','Major':'Rare','Rev':'Rare','Dr':'Rare'\n",
        "    })\n",
        "\n",
        "# Recreate TicketPrefix2 if missing\n",
        "if \"TicketPrefix2\" not in df.columns:\n",
        "    def ticket_prefix(t):\n",
        "        t = str(t).replace('.', '').replace('/', '').strip()\n",
        "        parts = t.split()\n",
        "        pref = ''.join([p for p in parts if not p.isdigit()])\n",
        "        return pref if pref != \"\" else \"NONE\"\n",
        "\n",
        "    df[\"TicketPrefix\"] = df[\"Ticket\"].apply(ticket_prefix)\n",
        "    top_ticket_prefixes = df[\"TicketPrefix\"].value_counts().nlargest(20).index.tolist()\n",
        "    df[\"TicketPrefix2\"] = df[\"TicketPrefix\"].apply(lambda x: x if x in top_ticket_prefixes else \"OTHER\")\n",
        "\n",
        "# Recreate Deck if missing\n",
        "if \"Deck\" not in df.columns:\n",
        "    df[\"Cabin\"] = df[\"Cabin\"].fillna(\"Unknown\")\n",
        "    df[\"Deck\"] = df[\"Cabin\"].astype(str).str[0]\n",
        "    df[\"Deck\"].replace(\"n\", \"Unknown\", inplace=True)\n"
      ],
      "metadata": {
        "id": "Mko9kvAHacwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10) Encode categorical columns - keep manageable cardinality\n",
        "# For TicketPrefix: keep top prefixes only, others mapped to \"OTHER\"\n",
        "top_ticket_prefixes = df[\"TicketPrefix\"].value_counts().nlargest(20).index.tolist()\n",
        "df[\"TicketPrefix2\"] = df[\"TicketPrefix\"].apply(lambda x: x if x in top_ticket_prefixes else \"OTHER\")\n",
        "\n",
        "# Titles one-hot\n",
        "df = pd.get_dummies(df, columns=[\"Title\",\"TicketPrefix2\",\"Deck\"], drop_first=True)\n"
      ],
      "metadata": {
        "id": "YbzN-7pmaKdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11) Features list - include leak signals and engineered features\n",
        "base_features = [\n",
        "    \"Pclass\",\"Sex\",\"Age\",\"Fare\",\"FamilySize\",\"IsAlone\",\"FarePerPerson\",\n",
        "    \"SurnameSurvivalRate\",\"SurnameCount\",\"TicketSurvivalRate\",\"TicketCount\",\n",
        "    \"FamilySizeSurvivalRate\",\"DeckSurvivalRate\",\"DeckCount\",\"TicketGroup\"\n",
        "]\n",
        "\n",
        "# add newly created dummies to feature list\n",
        "dummies = [c for c in df.columns if c.startswith((\"Title_\",\"TicketPrefix2_\",\"Deck_\"))]\n",
        "features = base_features + dummies\n"
      ],
      "metadata": {
        "id": "CwhLzflbaMMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12) Split back to train / test\n",
        "train_df = df.iloc[:len(train)].copy()\n",
        "test_df  = df.iloc[len(train):].copy()\n",
        "\n",
        "# 13) Prepare ML train data\n",
        "X = train_df[features].fillna(0)\n",
        "y = train_df[\"Survived\"].astype(int)\n",
        "\n",
        "X_test = test_df[features].fillna(0)\n",
        "\n",
        "# Convert to numeric dtypes for CatBoost\n",
        "X = X.astype(\"float32\")\n",
        "X_test = X_test.astype(\"float32\")"
      ],
      "metadata": {
        "id": "VoKTqL2jaiPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------\n",
        "# HARD RESET: remove duplicate columns everywhere\n",
        "# ---------------------------------------------------\n",
        "\n",
        "# Remove duplicates in df\n",
        "df = df.loc[:, ~df.columns.duplicated()]\n",
        "\n",
        "# Rebuild train_df and test_df cleanly\n",
        "train_df = df.iloc[:len(train)].copy()\n",
        "test_df  = df.iloc[len(train):].copy()\n",
        "\n",
        "# Rebuild feature list cleanly\n",
        "dummies = [c for c in df.columns if c.startswith((\"Title_\", \"TicketPrefix2_\", \"Deck_\"))]\n",
        "\n",
        "base_features = [\n",
        "    \"Pclass\", \"Sex\", \"Age\", \"Fare\", \"FamilySize\", \"IsAlone\", \"FarePerPerson\",\n",
        "    \"SurnameSurvivalRate\", \"SurnameCount\",\n",
        "    \"TicketSurvivalRate\", \"TicketCount\",\n",
        "    \"FamilySizeSurvivalRate\", \"DeckSurvivalRate\", \"DeckCount\",\n",
        "    \"TicketGroup\"\n",
        "]\n",
        "\n",
        "features = base_features + dummies\n",
        "\n",
        "# Remove any duplicates from features list\n",
        "features = list(dict.fromkeys(features))\n",
        "\n",
        "# Prepare train/test\n",
        "X = train_df[features].fillna(0).astype(\"float32\")\n",
        "y = train_df[\"Survived\"].astype(int)\n",
        "\n",
        "X_test = test_df[features].fillna(0).astype(\"float32\")\n",
        "\n",
        "print(\"Features Count:\", len(features))\n",
        "print(\"Unique Columns:\", len(df.columns))\n",
        "print(\"Shape X:\", X.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vf-6lu2fa3Sl",
        "outputId": "046e1c09-8410-4037-f8b7-00143fa1352d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features Count: 47\n",
            "Unique Columns: 57\n",
            "Shape X: (891, 47)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[x for x in df.columns if df.columns.duplicated()[df.columns.get_loc(x)]]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meBnSfvVa_n9",
        "outputId": "1549c156-d925-4917-fe69-9c6ab04f4958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 14) Train a strong CatBoost model\n",
        "cat = CatBoostClassifier(\n",
        "    iterations=2000,\n",
        "    learning_rate=0.03,\n",
        "    depth=6,\n",
        "    random_seed=42,\n",
        "    verbose=0,\n",
        "    early_stopping_rounds=100\n",
        ")\n",
        "\n",
        "cat.fit(X, y)\n",
        "\n",
        "# Obtain probability predictions for test\n",
        "proba_test = cat.predict_proba(X_test)[:,1]\n",
        "\n",
        "# Put initial ML predictions in the test dataframe\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "test_df[\"ml_proba\"] = proba_test\n",
        "test_df[\"ml_pred\"] = (test_df[\"ml_proba\"] >= 0.5).astype(int)"
      ],
      "metadata": {
        "id": "HZYAwWoralaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# STEP 15 — RULE-BASED OVERRIDE ENGINE (SAFE VERSION)\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "# Start with all Survived_final = NaN so rules can overwrite\n",
        "test_df[\"Survived_final\"] = np.nan\n",
        "\n",
        "# A) FAMILY (Surname) based deterministic survival (from train)\n",
        "if \"Surname\" in test_df.columns:\n",
        "    survived_surnames = surname_stats[\n",
        "        (surname_stats[\"SurnameSurvivalRate\"] == 1.0) &\n",
        "        (surname_stats[\"SurnameCount\"] >= 1)\n",
        "    ][\"Surname\"].tolist()\n",
        "\n",
        "    dead_surnames = surname_stats[\n",
        "        (surname_stats[\"SurnameSurvivalRate\"] == 0.0) &\n",
        "        (surname_stats[\"SurnameCount\"] >= 1)\n",
        "    ][\"Surname\"].tolist()\n",
        "\n",
        "    test_df.loc[test_df[\"Surname\"].isin(survived_surnames), \"Survived_final\"] = 1\n",
        "    test_df.loc[test_df[\"Surname\"].isin(dead_surnames),    \"Survived_final\"] = 0\n",
        "\n",
        "\n",
        "# B) TICKET-LEVEL SURVIVAL (deterministic)\n",
        "if \"TicketSurvivalRate\" in test_df.columns:\n",
        "    test_df.loc[(test_df[\"TicketSurvivalRate\"] == 1.0), \"Survived_final\"] = 1\n",
        "    test_df.loc[(test_df[\"TicketSurvivalRate\"] == 0.0), \"Survived_final\"] = 0\n",
        "\n",
        "\n",
        "# C) CHILDREN PRIORITY RULE\n",
        "test_df.loc[test_df[\"Age\"] < 12, \"Survived_final\"] = 1\n",
        "\n",
        "\n",
        "# D) DECK-LEVEL SURVIVAL RULE\n",
        "if \"DeckSurvivalRate\" in test_df.columns:\n",
        "    test_df.loc[test_df[\"DeckSurvivalRate\"] > 0.80, \"Survived_final\"] = 1\n",
        "    test_df.loc[test_df[\"DeckSurvivalRate\"] < 0.20, \"Survived_final\"] = 0\n",
        "\n",
        "\n",
        "# E) MALE 3RD CLASS RULE (historically mostly died)\n",
        "test_df.loc[\n",
        "    (test_df[\"Sex\"] == 0) &\n",
        "    (test_df[\"Pclass\"] == 3) &\n",
        "    (test_df[\"Age\"] > 12),\n",
        "    \"Survived_final\"\n",
        "] = 0\n",
        "\n",
        "\n",
        "# F) TICKET GROUP SURVIVAL RULE\n",
        "if \"TicketGroupSurvRate\" in test_df.columns:\n",
        "    test_df.loc[(test_df[\"TicketGroupSurvRate\"] == 1), \"Survived_final\"] = 1\n",
        "    test_df.loc[(test_df[\"TicketGroupSurvRate\"] == 0), \"Survived_final\"] = 0\n",
        "\n",
        "\n",
        "# G) EXTREME ML OVERRIDES\n",
        "# (If ML is extremely confident, accept it)\n",
        "test_df.loc[test_df[\"ml_proba\"] > 0.98, \"Survived_final\"] = 1\n",
        "test_df.loc[test_df[\"ml_proba\"] < 0.02, \"Survived_final\"] = 0\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# FINAL FILL for rows not covered by rules\n",
        "# (Use ML prediction for remaining)\n",
        "# -----------------------------------------------------------\n",
        "test_df[\"Survived_final\"] = test_df[\"Survived_final\"].fillna(test_df[\"ml_pred\"]).astype(int)\n",
        "\n",
        "print(\"Rule-based predictions applied successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeTdT2wBan_1",
        "outputId": "5d7f3351-5ef8-404e-cc47-60ff49e2ede7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rule-based predictions applied successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# STEP 16 — Prepare Kaggle Submission\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "# Create submission DataFrame\n",
        "submission = pd.DataFrame({\n",
        "    \"PassengerId\": test_df[\"PassengerId\"].astype(int),\n",
        "    \"Survived\": test_df[\"Survived_final\"].astype(int)\n",
        "})\n",
        "\n",
        "# Sort to match required format (not mandatory but good practice)\n",
        "submission = submission.sort_values(\"PassengerId\").reset_index(drop=True)\n",
        "\n",
        "print(submission.head())\n",
        "print(submission.tail())\n",
        "print(\"Submission shape:\", submission.shape)\n"
      ],
      "metadata": {
        "id": "qaX_jZckbgES",
        "outputId": "b397591b-5a7b-4005-82fb-c12239aeb2fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived\n",
            "0          892         0\n",
            "1          893         1\n",
            "2          894         0\n",
            "3          895         0\n",
            "4          896         1\n",
            "     PassengerId  Survived\n",
            "413         1305         0\n",
            "414         1306         1\n",
            "415         1307         0\n",
            "416         1308         0\n",
            "417         1309         1\n",
            "Submission shape: (418, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# STEP 17 — Save submission file for Kaggle\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "submission_file = \"submission.csv\"\n",
        "submission.to_csv(submission_file, index=False)\n",
        "\n",
        "print(\"Saved:\", submission_file)\n"
      ],
      "metadata": {
        "id": "LTsGFlvlbgmY",
        "outputId": "15fe306d-ef28-487f-9b40-871d4eddd88e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: submission.csv\n"
          ]
        }
      ]
    }
  ]
}